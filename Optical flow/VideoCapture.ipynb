{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e636463e94f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create old frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mold_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Lucas kanade params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('TGS.mp4')\n",
    " \n",
    "# Create old frame\n",
    "_, frame = cap.read()\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# Lucas kanade params\n",
    "lk_params = dict(winSize = (15, 15),\n",
    "                 maxLevel = 4,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    " \n",
    "# Mouse function\n",
    "def select_point(event, x, y, flags, params):\n",
    "    global point, point_selected, old_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x, y)\n",
    "        point_selected = True\n",
    "        old_points = np.array([[x, y]], dtype=np.float32)\n",
    " \n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    " \n",
    "point_selected = False\n",
    "point = ()\n",
    "old_points = np.array([[]])\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    if point_selected is True:\n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), 2)\n",
    " \n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, old_points, None, **lk_params)\n",
    "        old_gray = gray_frame.copy()\n",
    "        old_points = new_points\n",
    " \n",
    "        x, y = new_points.ravel()\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    " \n",
    " \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "__author__ = 'Seran'\n",
    " \n",
    "# 영상의 의미지를 연속적으로 캡쳐할 수 있게 하는 class\n",
    "vidcap = cv2.VideoCapture('TGS.mp4')\n",
    " \n",
    "count = 0\n",
    " \n",
    "while(vidcap.isOpened()):\n",
    "    ret, image = vidcap.read()\n",
    " \n",
    "    if(int(vidcap.get(1)) % 50 == 0):\n",
    "        print('Saved frame number : ' + str(int(vidcap.get(1))))\n",
    "        cv2.imwrite(\"../images/frame%d.jpg\" % count, image)\n",
    "        print('Saved frame%d.jpg' % count)\n",
    "        count += 1\n",
    "        \n",
    "vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
